{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the data from Part 1 with the data from Part 2 to create a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "from IPython.display import display  \n",
    "\n",
    "## Joining data from Part 1 with the data from Part 2 to create a new dataframe:\n",
    "  \n",
    "# First DataFrame  \n",
    "dataFrame1 = pd.DataFrame({'Restaurants': ['Anitas', 'Taste Of Italy', 'Taqueria Gardenias', 'Golden Diner'],  \n",
    "                    'Distance': ['33', '5', '15', '45'],  \n",
    "                    'Ratings':[4.5,4.5,4.5,5]}) \n",
    "  \n",
    "# Second DataFrame    \n",
    "dataFrame2 = pd.DataFrame({'Bike Stations': ['Lexington Ave', '5TH Ave', 'W 29TH St', 'W 29TH St'],  \n",
    "                    'Name': ['Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station'],  \n",
    "                    'Slots':[1, 10, 0, 3]})  \n",
    "\n",
    "## Third DataFrame\n",
    "dataFrame3 = pd.DataFrame({'Latitude': ['40.734786', '40.737604', '40.724605', '40.728745'],  \n",
    "                    'Longitude': ['-74.050444', '-74.052478', '-74.078406', '-74.032108'],  \n",
    "                    'Number of Bikes':[10,9,5,23]})  \n",
    "\n",
    "frames = [dataFrame1, dataFrame2, dataFrame3]  \n",
    "  \n",
    "result = pd.concat(frames)  \n",
    "display(result)  \n",
    "\n",
    "## Joining data from Part 1 with the data from Part 2 to create a new dataframe:\n",
    "\n",
    "dataFrame1 = pd.DataFrame({'Bike Stations': ['W 100 St & Manhattan Ave', '7 Ave & Central Park South', 'Bedford Ave & Bergen St', '28 St & 41 Ave'],  \n",
    "                    'Ratings': ['4.5', '4.5', '4.5', '5'], \n",
    "                    'Restaurants':['Anitas', 'Taste Of Italy', 'Taqueria Gardenias', 'Golden Diner'],\n",
    "                    'Distance':['33', '5', '15', '45'],\n",
    "                    'Slots':['1', '10', '0', '3'],\n",
    "                    'Renting':['0', '12', '7', '4'],\n",
    "                    'Returned':['0', '1', '10', '8'],\n",
    "                    'Latitude': ['40.734786', '40.737604', '40.724605', '40.728745'],  \n",
    "                    'Longitude': ['-74.050444', '-74.052478', '-74.078406', '-74.032108'],  \n",
    "                    'Number of Bikes':[12,19,0,13]})  \n",
    "  \n",
    "  \n",
    "frames = [dataFrame1]  \n",
    "  \n",
    "result = pd.concat(frames)  \n",
    "display(result) \n",
    "\n",
    "## finding data before the merge\n",
    "def yelp_request(lat,long):\n",
    "    url= f\"https://api.yelp.com/v3/businesses/search?latitude={lat}&longitude={long}&radius=1000&categories=restaurant&sort_by=best_match&limit=20\"\n",
    "    \n",
    "    headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"bearer your_api_key\"\n",
    "}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    num_poi = len(response[\"businesses\"])\n",
    "    \n",
    "    print(response.text)\n",
    "\n",
    "    #  calling the data before the merge\n",
    "for row in range(len(df)):\n",
    "    lat = df.iloc[row,0]\n",
    "    long = df.iloc[row,1]\n",
    "    \n",
    "    yelp_request(lat,long)\n",
    "    break\n",
    "\n",
    "## Three dataframes\n",
    "\n",
    " df = pd.DataFrame(\n",
    "           {\"Restaurants\" : ['Main & New York', 'Melrose', 'Aberdeen', 'Mainway'], \n",
    "            \"Longitude\" : ['3212', '3207', '3193', '3199'],\n",
    "            \"Number of Bikes\" : [10, 11, 12, 11]},\n",
    "         index = [1, 2, 3, 4])\n",
    "\n",
    " df = pd.DataFrame(\n",
    "           {\"Bike Stations\" : ['Lexington Ave', '5TH Ave', 'W 29TH St', 'W 29TH St'], \n",
    "            \"Name\" : ['Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station'],\n",
    "            \"Number of Bikes\" : [12, 19, 0, 13]},\n",
    "         index = [1, 2, 3, 4])\n",
    "\n",
    " df = pd.DataFrame(\n",
    "           {'Latitude' : ['40.734786', '40.737604', '40.724605', '40.728745'], \n",
    "            \"Longitude\" : ['-74.050444', '-74.052478', '-74.078406', '-74.032108'],\n",
    "            \"Number of Bikes\" : [1, 10, 5, 16]},\n",
    "         index = [1, 2, 3, 4])\n",
    "\n",
    "frames = [dataFrame1, dataFrame2, dataFrame3]  \n",
    "  \n",
    "result = pd.concat(frames)  \n",
    "display(result) \n",
    "  \n",
    "\n",
    "## DataFrame\n",
    "dataFrame1 = pd.DataFrame({'Restaurants': ['Anitas', 'Taste Of Italy', 'Taqueria', 'Hot-Dog Jays', \n",
    "                        'Bike Stations', 'Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station']})    \n",
    "  \n",
    "frames = [dataFrame1, dataFrame2, dataFrame3]  \n",
    "  \n",
    "result = pd.concat(frames)  \n",
    "display(result)  \n",
    " \n",
    "\n",
    "## Combining 3 dataframes\n",
    "\n",
    "import pandas as pd  \n",
    "from IPython.display import display  \n",
    "  \n",
    "# First DataFrame  \n",
    "dataFrame1 = pd.DataFrame({'Bike Stations': ['Main & New York', 'Melrose', 'Aberdeen', 'Mainway'],  \n",
    "                    'Names': ['Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station'],  \n",
    "                    'Renting':['4', '7', '21', '9']})  \n",
    "  \n",
    "# Second DataFrame    \n",
    "dataFrame2 = pd.DataFrame({'Restaurants': ['Anitas', 'Taste Of Italy', 'Taqueria', 'Hot-Dog Jays'],  \n",
    "                    'Distance': ['33', '5', '15', '45'],  \n",
    "                    'Ratings':[4.5,4.5,4.5,5]})  \n",
    "\n",
    "## Third DataFrame\n",
    "dataFrame3 = pd.DataFrame({'Latitude': ['40.734786', '40.737604', '40.724605', '40.728745'],  \n",
    "                    'Longitude': ['-74.050444', '-74.052478', '-74.078406', '-74.032108'],  \n",
    "                    'Number of Bikes':[10,9,5,23]})  \n",
    "  \n",
    "                      \n",
    "  \n",
    "frames = [dataFrame1, dataFrame2, dataFrame3]  \n",
    "  \n",
    "result = pd.concat(frames)  \n",
    "display(result)  \n",
    "\n",
    "\n",
    "## Joining data from Part 1 with the data from Part 2 to create a new dataframe:\n",
    "\n",
    "import pandas as pd  \n",
    "from IPython.display import display  \n",
    "  \n",
    "# First DataFrame  \n",
    "dataFrame1 = pd.DataFrame({'Bike Stations': ['Main & New York', 'Melrose', 'Aberdeen', 'Mainway'],  \n",
    "                    'Longitude': ['-74.050444', '-74.052478', '-74.078406', '-74.032108'],  \n",
    "                    'Latitude':[40.734786, 40.737604, 40.724605, 40.728745]})  \n",
    "  \n",
    "# Second DataFrame    \n",
    "dataFrame2 = pd.DataFrame({'Restaurants': ['Lexington Ave', '5TH Ave', 'W 29TH St', 'W 29TH St'],  \n",
    "                    'Names': [Citi Bike Station, 'Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station'],  \n",
    "                    'Number of Bikes':[12,19,0,13]}) \n",
    "  \n",
    "  \n",
    "frames = [dataFrame1, dataFrame2]  \n",
    "  \n",
    "result = pd.concat(frames)  \n",
    "display(result)  \n",
    "\n",
    "## Final database\n",
    "\n",
    "FinalDB.to_sql(name='CombinedData', con=con)\n",
    "\n",
    "conn = sqlite3.connect('bikes.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "cursor.execute(\"SELECT * FROM Combined_Database\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide a visualization that you used as part of your EDA process. Explain the initial pattern or relationship you discoved through this visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I had imported the libraries we will require for performing EDA.\n",
    "## These include NumPy, Pandas, Matplotlib, and Seaborn.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "##Matplotlib is building the font cache; this may take a moment.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "## Visulisation:\n",
    "\n",
    "## Step 1) Exploring the data:\n",
    "\n",
    "## Loading csv file\n",
    "df = pd.read_csv('NYC-BikeShare-2015-2017-combined.csv')\n",
    "df\n",
    "\n",
    "## Rows + columns\n",
    "df.shape \n",
    "\n",
    "## Gathering details\n",
    "df.info()\n",
    "\n",
    "## Gathering neighborhoods\n",
    "neighborhoods_subset = pd.read_csv(\"NYC-BikeShare-2015-2017-combined.csv\")\n",
    "neighborhoods_subset.head()\n",
    "\n",
    "## Summary of data\n",
    "df.describe()\n",
    "\n",
    "## Creating plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Adding Figure and Axes objects \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plotting the data \n",
    "ax.hist(df['BikeStations'])\n",
    "\n",
    "# Customize other aspects of the plot\n",
    "ax.set_title('Histogram of BikeStations')\n",
    "ax.set_xlabel('Bikes')\n",
    "ax.set_ylabel('Amount')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "## Creating 2 graphs\n",
    "fig, axes = plt.subplots(nrows = 1, \n",
    "                         ncols = 2, \n",
    "                         figsize=(14, 5)       \n",
    "                        )\n",
    "\n",
    "# Plot 0\n",
    "axes[0].hist(df['Restaurants'])\n",
    "axes[0].set_title('Histogram of Restaurants')\n",
    "axes[0].set_xlabel('Restaurants')\n",
    "axes[0].set_ylabel('Names')\n",
    "\n",
    "# Plot 1\n",
    "axes[1].hist(df['Bike Stations'], bins=30, color='green')\n",
    "axes[1].set_title('Histogram of Bike Stations')\n",
    "axes[1].set_xlabel('Bike Stations')\n",
    "axes[1].set_ylabel('Names')\n",
    "axes[1].set_xlim(left=0)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### Explain the initial pattern or relationship you discovered through this visualization:\n",
    "\n",
    "The pattern or relationship that I had discovered through this visualization is that the \n",
    "bike stations run out of bikes fast and that there are not enough bikes for the whole city."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all your results in an SQLite3 database (remember, SQLite stores its databases as files in your local machine - make sure to create your database in your project's data/ directory!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Installed SQLite extension in VSCode\n",
    "\n",
    "## Imported sqlite3 on Jupyter Lab\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "def create_connection(path):\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = sqlite3.connect(path)\n",
    "        print(\"Connection to SQLite DB successful\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "    return connection\n",
    "\n",
    "## Created connection\n",
    "connection = create_connection(\"E:\\\\sm_app.sqlite\")\n",
    "Connection to SQLite DB successful\n",
    "\n",
    "## Dataframe\n",
    "## Putting my parsed results into a SQlite database\n",
    "\n",
    "## Importing required packages\n",
    "import pandas as pd\n",
    "\n",
    "## This will transform my results into a JSON file/format then after I will convert to a database\n",
    "first_json = pd.read_json(data)\n",
    "first_json.head()\n",
    "\n",
    "## This normalizes to dataframe that will go on SQlite3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "first_json = pd.json_normalize(res_json)\n",
    "first_json.head()\n",
    "\n",
    "## Next step is to convert my JSON file into a database that will go into SQlite database\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('/Users/ibadetazemi/Desktop/Data Science/bikes.db')\n",
    "first_json.to_sql('CityBike', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data before and after the join to validate your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Installing required packages\n",
    "pip install pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "## Validating the data frame is empty or not \n",
    "def read_file():\n",
    "    df = pd.read_csv(filename)\n",
    "    if(df.empty):\n",
    "        print ('CSV file is empty')\n",
    "    else:\n",
    "        print ('CSV file is not empty')\n",
    "        return df\n",
    "    \n",
    "\n",
    "## Pass the file name as the argument as below :\n",
    "filename ='C:\\\\Users\\\\nfinity\\\\Downloads\\\\Data sets\\\\citybikes.csv'\n",
    "\n",
    "## Call the function as belows is\n",
    "df = read_file()\n",
    "\n",
    "## Using pandas library to determine the csv data datatype by iterating the rows :\n",
    "import pandas as pd\n",
    "df = pd.read_csv(citybikes.csv', nrows=2)\n",
    "for dtype in df.dtypes.iteritems():\n",
    "    print(dtype)\n",
    "                 \n",
    "## Or also we can easily know the data types by using below code :\n",
    "df.types\n",
    "                 \n",
    "## Processing the matched columns we are going to processing only matched columns between validation and input data arrange the columns based on the column name as below.\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv('citybikes.csv')\n",
    "df = df[sorted(data)]\n",
    "validation = df\n",
    "validation['chk'] = validation['Trip Durarion'].apply(lambda x: True if x in df else False)\n",
    "validation = validation[validation['chk'] == True].reset_index()\n",
    "df\n",
    "                 \n",
    "## Check Data Type convert as Date column we are going to check the columns data types  \n",
    "## And convert the date column as below code:\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        try:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "        except ValueError:\n",
    "            pass\n",
    "print(df.dtypes)\n",
    "                 \n",
    "                 \n",
    "## validate data to check missing values \n",
    "for col in df.columns:\n",
    "    miss = df[col].isnull().sum()\n",
    "    if miss>0:\n",
    "        print(\"{} has {} missing value(s)\".format(col,miss))\n",
    "    else:\n",
    "        print(\"{} has NO missing value!\".format(col))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
