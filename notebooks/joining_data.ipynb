{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Joining data from Part 1 with the data from Part 2 to create a new dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd  \n",
    "from IPython.display import display  \n",
    "\n",
    "# Merging/Combining 2 csvs into 1 csv\n",
    "import pandas as pd\n",
    "\n",
    "files = ['citybikes.csv', 'restaurants.csv']\n",
    "df = pd.DataFrame()\n",
    "for file in files:\n",
    "    data = pd.read_csv(file)\n",
    "    df = pd.concat([df, data], axis=0)\n",
    "df.to_csv('citybikes.csv', index=False)\n",
    "\n",
    "## Joining data from Part 1 with the data from Part 2 to create a new dataframe:\n",
    "\n",
    "# Will now create a for loop to count for POI Foursquare for bike stations\n",
    "foursquare_df=[]\n",
    "# Parsing through results\n",
    "for i in list_foursquare0:\n",
    "    foursquare_df.append(i['results'])\n",
    "# Parsing through results\n",
    "foursquare_df=[]\n",
    "for n in range(len(foursquare_df)):\n",
    "    foursquare_df.append(len(foursquare_df[n]))\n",
    "\n",
    "# Yelp API \n",
    "with open ('/Users/ibadetazemi/statistical-modelling-project-2023/Desktop/Data Science/yelp.json', 'r') as f:\n",
    "     list_yelp1=json.load(f)\n",
    "\n",
    "list_yelp1=list_yelp1[0:100]\n",
    "\n",
    "## Reading the response from the json file\n",
    "res_json = response.json()\n",
    "res_json\n",
    "\n",
    "# List\n",
    "foursquare_df=[]\n",
    "Yelp_df=[]\n",
    "\n",
    "# Checking count\n",
    "len(Yelp_df)\n",
    "\n",
    "# Joining part 1 and part 2 of my data to citybikes_df\n",
    "citybikes_df[\"foursquare_df\"]=foursquare_df\n",
    "citybikes_df[\"yelp_df\"]=yelp_df\n",
    "citybikes_df[\"restaurants_df\"]=restaurants_df\n",
    "\n",
    "# Viewing csv\n",
    "citybikes\n",
    "\n",
    "# Converting dataframes into citybikes csv\n",
    "citybikes_df.to_csv('citybikes.csv')\n",
    "\n",
    "## Combining 2 csvs into 1 CSV (yelp + foursquare + citybikes)\n",
    "import pandas as pd\n",
    "\n",
    "foursquare_df = pd.read_csv('citybikes.csv')\n",
    "yelp_df = pd.read_csv('citybikes.csv')\n",
    "restaurants_df = pd.read_csv('restaurants.csv')\n",
    "citybikes_df = pd.merge(foursquare_df, yelp_df, restaurants_df, on='ID', how='inner')\n",
    "citybikes_df.to_csv('citybikes.csv', index=False)\n",
    "\n",
    "## Combining 2 csvs into 1 CSV (citybikes + yelp_foursquare)\n",
    "import pandas as pd\n",
    "\n",
    "files = ['citybikes.csv', 'yelp_foursquare.csv']\n",
    "df = pd.DataFrame()\n",
    "for file in files:\n",
    "    data = pd.read_csv(file)\n",
    "    df = pd.concat([df, data], axis=0)\n",
    "df.to_csv('citybikes.csv', index=False)\n",
    "\n",
    "## Joining data from Part 1 with the data from Part 2 to create a new dataframe: \n",
    "\n",
    "dataFrame1 = pd.DataFrame({'Bike Stations': ['Lexington Ave', '5TH Ave', 'W 29TH St', 'W 29TH St'],  \n",
    "                    'Station Name': ['Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station'],\n",
    "                    'Restaurants':['Anitas', 'Taste Of Italy', 'Taqueria Gardenias', 'Golden Diner'],\n",
    "                    'Ratings': ['4.5', '4.5', '4.5', '5'], \n",
    "                    'Distance':['33', '5', '15', '45'],\n",
    "                    'Slots':['1', '10', '0', '3'],\n",
    "                    'Renting':['0', '12', '7', '4'],\n",
    "                    'Reviews':['43', '15', '36', '60'],\n",
    "                    'POI_Count':['20', '15', '18', '23'],\n",
    "                    'Returned':['0', '1', '10', '8'],\n",
    "                    'Latitude': ['40.734786', '40.737604', '40.724605', '40.728745'],  \n",
    "                    'Longitude': ['-74.050444', '-74.052478', '-74.078406', '-74.032108'],  \n",
    "                    'Number of Bikes':[12,19,0,13]})  \n",
    "  \n",
    "  \n",
    "frames = [dataFrame1]  \n",
    "  \n",
    "result = pd.concat(frames)  \n",
    "display(result) \n",
    "\n",
    "## converting dataframe to CSV:\n",
    "dataFrame1.to_csv(\"citybikes.csv\")\n",
    "  \n",
    "# DataFrames\n",
    "dataFrame1 = pd.DataFrame({'Restaurants': ['Anitas', 'Taste Of Italy', 'Taqueria Gardenias', 'Golden Diner'],  \n",
    "                    'Distance': ['33', '5', '15', '45'],  \n",
    "                    'Ratings':[4.5,4.5,4.5,5]}) \n",
    "  \n",
    "   \n",
    "dataFrame2 = pd.DataFrame({'Bike Stations': ['Lexington Ave', '5TH Ave', 'W 29TH St', 'W 29TH St'],  \n",
    "                    'Station Name': ['Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station'],\n",
    "                    'Reviews':['43', '15', '36', '60'],\n",
    "                    'POI_Count':['20', '15', '18', '23'],  \n",
    "                    'Renting': ['34', '40', '1', '5'],\n",
    "                    'Returned': ['5', '22', '12', '0'],\n",
    "                    'Slots':[1, 10, 0, 3]})  \n",
    "\n",
    "\n",
    "dataFrame3 = pd.DataFrame({'Latitude': ['40.734786', '40.737604', '40.724605', '40.728745'],  \n",
    "                    'Longitude': ['-74.050444', '-74.052478', '-74.078406', '-74.032108'],  \n",
    "                    'Number of Bikes':[10,9,5,23]})  \n",
    "\n",
    "frames = [dataFrame1, dataFrame2, dataFrame3]  \n",
    "  \n",
    "result = pd.concat(frames)  \n",
    "display(result)  \n",
    "\n",
    "## converting dataframe to CSV\n",
    "dataFrame1.to_csv(\"citybikes.csv\")\n",
    "\n",
    "# File path for CSV file:\n",
    "csv_dataFrame1 = \"citybikes.csv\"\n",
    "\n",
    "# Saving file to CSV:\n",
    "dataFrame1.to_csv(csv_dataFrame1, index=False\n",
    "\n",
    "## finding data before the merge\n",
    "def yelp_request(lat,long):\n",
    "    url= f\"https://api.yelp.com/v3/businesses/search?latitude={lat}&longitude={long}&radius=1000&categories=restaurant&sort_by=best_match&limit=20\"\n",
    "    \n",
    "    headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"bearer your_api_key\"\n",
    "}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    num_poi = len(response[\"businesses\"])\n",
    "    \n",
    "    print(response.text)\n",
    "\n",
    "    #  calling the data before the merge\n",
    "for row in range(len(df)):\n",
    "    lat = df.iloc[row,0]\n",
    "    long = df.iloc[row,1]\n",
    "    \n",
    "    yelp_request(lat,long)\n",
    "    break\n",
    "\n",
    "## Joining data from Part 1 with the data from Part 2 to create a new dataframe:\n",
    "\n",
    " df = pd.DataFrame(\n",
    "           {\"Latitude\" : [-74.050444', '-74.052478', '-74.078406', '-74.032108''], \n",
    "            \"Longitude\" : ['40.734786', '40.737604', '40.724605', '40.728745'],\n",
    "            \"Number of Bikes\" : [10, 11, 12, 11]},\n",
    "         index = [1, 2, 3, 4])\n",
    "\n",
    " df = pd.DataFrame(\n",
    "           {\"Slots\" : ['1', '0', '1', '5'], \n",
    "            \"Bike Stations\" : ['Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station'],\n",
    "            \"Returned\" : ['0', '18', '6', '23'],\n",
    "            \"Renting\" : [12, 19, 0, 13]},\n",
    "         index = [1, 2, 3, 4])\n",
    "\n",
    " df = pd.DataFrame(\n",
    "           {'Restaurants' : ['Anitas', 'Taste Of Italy', 'Taqueria', 'Hot-Dog Jays'], \n",
    "            \"Distance\" : ['34', '15', '5', '40'],\n",
    "            \"Ratings\" : [4.5, 4.5, 4.5, 5]},\n",
    "         index = [1, 2, 3, 4])\n",
    "\n",
    "frames = [dataFrame1, dataFrame2, dataFrame3]  \n",
    "  \n",
    "result = pd.concat(frames)  \n",
    "display(result)  \n",
    " \n",
    "\n",
    "## Combining 3 dataframes\n",
    "\n",
    "import pandas as pd  \n",
    "from IPython.display import display  \n",
    "  \n",
    "# First DataFrame  \n",
    "dataFrame1 = pd.DataFrame({'Bike Stations': ['Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station'],  \n",
    "                    'Slots': ['3', '0', '15', '31'],  \n",
    "                    \"Returned\" : ['0', '18', '6', '23'],\n",
    "                    'Renting':[1,4,10,9]})  \n",
    "  \n",
    "# Second DataFrame    \n",
    "dataFrame2 = pd.DataFrame({'Restaurants': ['Lexington Ave', '5TH Ave', 'W 29TH St', 'W 29TH St'],  \n",
    "                    'Distance': ['Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station', 'Citi Bike Station'],  \n",
    "                    'Reviews':['43', '15', '36', '60'],\n",
    "                    'POI_Count':['20', '15', '18', '23'],\n",
    "                    'Ratings':[4.5,4.5,4.5,5]})  \n",
    "\n",
    "## Third DataFrame\n",
    "dataFrame3 = pd.DataFrame({'Latitude': ['40.734786', '40.737604', '40.724605', '40.728745'],  \n",
    "                    'Longitude': ['-74.050444', '-74.052478', '-74.078406', '-74.032108'],  \n",
    "                    'Number of Bikes':[10,9,5,23]})  \n",
    "  \n",
    "                      \n",
    "  \n",
    "frames = [dataFrame1, dataFrame2, dataFrame3]  \n",
    "  \n",
    "result = pd.concat(frames)  \n",
    "display(result)  \n",
    "\n",
    "\n",
    "## Joining data from Part 1 with the data from Part 2 to create a new dataframe:\n",
    "\n",
    "import pandas as pd  \n",
    "from IPython.display import display  \n",
    "  \n",
    "# DataFrame  \n",
    "dataFrame1 = pd.DataFrame({'Bike Stations': ['Main & New York', 'Melrose', 'Aberdeen', 'Mainway'],          \n",
    "                    'Longitude': ['-74.050444', '-74.052478', '-74.078406', '-74.032108'],  \n",
    "                    'Latitude':[40.734786, 40.737604, 40.724605, 40.728745]})  \n",
    "                    'Number of Bikes':[10,9,5,23]}) \n",
    "  \n",
    "# Second DataFrame    \n",
    "dataFrame2 = pd.DataFrame({'Restaurants': ['Lexington Ave', '5TH Ave', 'W 29TH St', 'W 29TH St'],  \n",
    "                    'Distance': ['34', '15', '5', '40'],  \n",
    "                    'Reviews':['43', '15', '36', '60'],\n",
    "                    'POI_Count':['20', '15', '18', '23'],\n",
    "                    'Ratings':[4.5,4.5,4.5,5]}) \n",
    "  \n",
    "  \n",
    "frames = [dataFrame1, dataFrame2]  \n",
    "  \n",
    "result = pd.concat(frames)  \n",
    "display(result) \n",
    "\n",
    "## converting dataframe to CSV\n",
    "dataFrame1.to_csv(\"citybikes.csv\")\n",
    "\n",
    "## converting dataframe to CSV\n",
    "import pandas as pd\n",
    "\n",
    "files = ['citybikes.csv', 'restaurants.csv']\n",
    "df = pd.DataFrame()\n",
    "for file in files:\n",
    "    data = pd.read_csv(file)\n",
    "    df = pd.concat([df, data], axis=0)\n",
    "df.to_csv('citybikes.csv', index=False)\n",
    "\n",
    "# Saving dataframe to CSV file\n",
    "DataFrame.to_csv(csv_joining_data, index=False)\n",
    "\n",
    "## Final database\n",
    "\n",
    "FinalDB.to_sql(name='citybikes', con=con)\n",
    "\n",
    "conn = sqlite3.connect('bikes.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "cursor.execute(\"SELECT * FROM citybikes_Database\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide a visualization that you used as part of your EDA process. Explain the initial pattern or relationship you discoved through this visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I had imported the libraries we will require for performing EDA.\n",
    "## These include NumPy, Pandas, Matplotlib, and Seaborn.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "##Matplotlib is building the font cache; this may take a moment.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "## Loading csv file\n",
    "citybikes = pd.read_csv('citybikes.csv')\n",
    "citybikes\n",
    "\n",
    "## Viewing data\n",
    "citybikes.describe()\n",
    "\n",
    "## Finding null values\n",
    "citybikes.isnull().sum()\n",
    "\n",
    "# Finding shape \n",
    "citybikes.shape\n",
    "\n",
    "# Finding first 5 rows\n",
    "citybikes.head()\n",
    "\n",
    "## This displays the information\n",
    "citybikes.info()\n",
    "\n",
    "# Cleaning the empty part at the bottom\n",
    "citybikes= citybikes.iloc[0:986]\n",
    "citybikes.tail()\n",
    "\n",
    "# Will now be replacing blank with 0 to convert to data float\n",
    "citybikes = citybikes.replace('..', 0)\n",
    "\n",
    "# Now will convert column (5 to 108) from object to float\n",
    "#citybikes.iloc[:, 3:105]=citybikes.iloc[:, 3:105].astype(float) \n",
    "citybikes.iloc[:, 3:125]= citybikes.iloc[:, 3:125].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Now will convert \"Time\" to object\n",
    "citybikes[\"Time\"] = pd.to_datetime(citybikes[\"Time\"].astype(str), format=\"%Y\", errors='coerce')\n",
    "citybikes.head()\n",
    "\n",
    "## EDA Visulisations:\n",
    "\n",
    "# Visualising our predictions - lmplot\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "sns.lmplot(x='POI_Count', y='Number of Bikes', data=citybikess, line_kws={'color': 'black'});\n",
    "\n",
    "# Scatterplot for Longitude + Latitude (EDA):\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(data=citybikes.iloc[:1000], \n",
    "             x=\"Longitude\", \n",
    "             y=\"Latitude\",\n",
    "             alpha = 0.7)\n",
    "\n",
    "plt.suptitle(\"Trip Insights\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Scatterplot for Restaurants (EDA):\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(data=citybikes.iloc[:1000], \n",
    "             x=\"Restaurants\", \n",
    "             y=\"Ratings\",\n",
    "             alpha = 0.7)\n",
    "\n",
    "plt.suptitle(\"Restaurant Insights\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Scatterplot for City Bikes (EDA):\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(data=citybikes.iloc[:1000], \n",
    "             x=\"Bike Stations\", \n",
    "             y=\"Slots\",\n",
    "             alpha = 0.7)\n",
    "\n",
    "plt.suptitle(\"Bikes Insights\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Scatterplot for available bikes in New York City\n",
    "fig_1=sns.scatterplot(data=citybikes,\n",
    "            y ='Latitude',\n",
    "            x ='Longitude',\n",
    "            hue='Number of Bikes',\n",
    "            size='Number of Bikes',\n",
    "            sizes=(0, 200))\n",
    "fig_1.set(title='Available bikes in New York City')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Scatterplot for restaurants in New York City\n",
    "fig_2=sns.scatterplot(data=citybikes,\n",
    "            y ='Latitude',\n",
    "            x ='Longitude',\n",
    "            hue='Ratings',\n",
    "            size='Ratings',\n",
    "            sizes=(0, 200))\n",
    "fig_2.set(title='Restaurants in New York City')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Pairplot for citybikes \n",
    "fig_5=sns.pairplot(data=citybikes,\n",
    "                    kind='reg', \n",
    "                    diag_kind='kde',\n",
    "                    plot_kws={'line_kws':{'color':'green'}})\n",
    "plt.show()\n",
    "\n",
    "## Pairplot to view data searching for outliers\n",
    "## selecting only integers creating a new variable using  'float64', 'int64'\n",
    "numeric=citybikes.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(data= numeric, annot=True)\n",
    "\n",
    "# EDA visualisations checking for outliers\n",
    "fig, axes = plt.subplots(2, 2, figsize=(19, 10))\n",
    "\n",
    "#matplotlib\n",
    "axes[0,0].hist(citybikes['Number of Bikes'])\n",
    "axes[0,0].set_title('[Matplotlib] Histogram of Number of Bikes')\n",
    "\n",
    "axes[0,1].boxplot(citybikes['Ratings'])\n",
    "axes[0,1].set_title('[Matplotlib] Box-Plot of Ratings')\n",
    "\n",
    "#seaborn\n",
    "sns.histplot(ax=axes[1,0], data=citybikes, x=\"Ratings\")\n",
    "axes[1,0].set_title('[Seaborn] Histogram of Restaurant Ratings')\n",
    "\n",
    "sns.boxplot(ax=axes[1,1], data=citybikes, y=\"Distance\")\n",
    "axes[1,1].set_title('[Seaborn] Box-Plot of Restaurant Distance')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Colormap\n",
    "custom_cmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "\n",
    "# Heatmap with custom colormap\n",
    "fig, ax = plt.subplots(1, 1, figsize=(17, 15))\n",
    "sns.heatmap(X.corr(), annot=True, cmap=custom_cmap)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Create a colormap (choose any colormap you like)\n",
    "custom_cmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "\n",
    "# Create the heatmap with the custom colormap\n",
    "fig, ax = plt.subplots(1, 1, figsize=(17, 15))\n",
    "sns.heatmap(X.corr(), annot=True, cmap=custom_cmap)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "## checking for outliers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(X.columns):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    sns.boxplot(data=X, y=col)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "## Scatterplot\n",
    "sns.stripplot(data=citybikes, x='Latitude', y='Number of Bikes', alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "## Bar Graph\n",
    "plt.figure(figsize=(6.4,4.8)) #default size\n",
    "sns.barplot(data=citybikes, x='Ratings', y='Number of Bikes') #averages with error bars\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Scatterplot \n",
    "sns.swarmplot(data=citybikes, x='Longitude', y='Latitude')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# sns.boxplot(x=citybikes['Ratings'])\n",
    "sns.boxplot(x=citybikes['Distance'], whis=4)\n",
    "\n",
    "# creating a histoplot\n",
    "citybikes.plot.hist()\n",
    "\n",
    "### Explain the initial pattern or relationship you discovered through this visualization:\n",
    "\n",
    "The pattern or relationship that I had discovered through this visualization is that the \n",
    "bike stations run out of bikes fast and that there are not enough bikes for the whole city.\n",
    "And there are outliers.\n",
    "\n",
    "## Step 1) Exploring the data:\n",
    "\n",
    "## Loading csv file\n",
    "citybikes = pd.read_csv('citybikes.csv')\n",
    "citybikes\n",
    "\n",
    "## Rows + columns\n",
    "citybikes.shape \n",
    "\n",
    "## Gathering details\n",
    "citybikes.info()\n",
    "\n",
    "## Gathering neighborhoods\n",
    "neighborhoods_subset = pd.read_csv(\"citybikes.csv\")\n",
    "neighborhoods_subset.head()\n",
    "\n",
    "## Summary of data\n",
    "citybikes.describe()\n",
    "\n",
    "## Creating plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Adding Figure and Axes objects \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plotting the data \n",
    "ax.hist(citybikes['Bike Stations'])\n",
    "\n",
    "# Customize other aspects of the plot\n",
    "ax.set_title('Histogram of Bike Stations')\n",
    "ax.set_xlabel('Distance')\n",
    "ax.set_ylabel('Number of Bikes')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "## Creating 2 graphs\n",
    "fig, axes = plt.subplots(nrows = 1, \n",
    "                         ncols = 2, \n",
    "                         figsize=(14, 5)       \n",
    "                        )\n",
    "\n",
    "# Plot 0\n",
    "axes[0].hist(citybikes['Restaurants'])\n",
    "axes[0].set_title('Histogram of Restaurants')\n",
    "axes[0].set_xlabel('Restaurants')\n",
    "axes[0].set_ylabel('Ratings')\n",
    "\n",
    "# Plot 1\n",
    "axes[1].hist(citybikes['Bike Stations'], bins=30, color='green')\n",
    "axes[1].set_title('Histogram of Bike Stations')\n",
    "axes[1].set_xlabel('Bike Stations')\n",
    "axes[1].set_ylabel('Slots')\n",
    "axes[1].set_xlim(left=0)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# pairplot\n",
    "citybikes=citybikes.groupby(\"Number of Bikes\").mean()\n",
    "\n",
    "for i in citybikes.columns:\n",
    "    plt.bar([\"Number of Bikes\",\"Slots\"],citybikes[i], color=['blue', 'orange'])\n",
    "    plt.xlabel(\"Type\")\n",
    "    plt.ylabel(i)\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all your results in an SQLite3 database (remember, SQLite stores its databases as files in your local machine - make sure to create your database in your project's data/ directory!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Installed SQLite extension in VSCode\n",
    "\n",
    "## Imported sqlite3 on Jupyter Lab\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "def create_connection(path):\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = sqlite3.connect(path')\n",
    "        print(\"Connection to SQLite DB successful\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "    return connection\n",
    "\n",
    "## Created connection\n",
    "connection = create_connection(\"E:\\\\sm_app.sqlite\")\n",
    "Connection to SQLite DB successful\n",
    "\n",
    "## Dataframe\n",
    "## Putting my parsed results into a SQlite database\n",
    "\n",
    "## Importing required packages\n",
    "import pandas as pd\n",
    "\n",
    "## This will transform my results into a JSON file/format then after I will convert to a database\n",
    "first_json = pd.read_json(data)\n",
    "first_json.head()\n",
    "\n",
    "## This normalizes to dataframe that will go on SQlite3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "first_json = pd.json_normalize(res_json)\n",
    "first_json.head()\n",
    "\n",
    "## Next step is to convert my JSON file into a database that will go into SQlite database\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('/Users/ibadetazemi/Desktop/Data Science/bikes.db')\n",
    "first_json.to_sql('CityBikes', conn, if_exists='replace', index=False)\n",
    "\n",
    "## \n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "# Creating a database \n",
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to a SQLite database \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(r\"/Users/ibadetazemi/Desktop/Data Science/bikes.db\")\n",
    "        print(sqlite3.version)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    create_connection(r\"/Users/ibadetazemi/Desktop/Data Science/bikes.db\")\n",
    "\n",
    "# Create a table in the SQLdatabase\n",
    "conn = sqlite3.connect(r\"/Users/ibadetazemi/Desktop/Data Science/bikes.db\")\n",
    "\n",
    "# Curser being created\n",
    "c = conn.cursor()\n",
    "\n",
    "# Creating a table\n",
    "c.execute(\"\"\"CREATE TABLE IF NOT EXISTS stations (\n",
    "                Station Name TEXT , \n",
    "                Number of Bikes INTERGER NOT NULL, \n",
    "                Slots INTERGER NOT NULL,\n",
    "                Longitude FLOAT NOT NULL,\n",
    "                Latitude FLOAT NOT NULL,\n",
    "                Returned FLOAT NOT NULL,\n",
    "                Renting FLOAT NOT NULL,\n",
    "                Ratings INTERGER NOT NULL,\n",
    "                Distance INTERGER NOT NULL\n",
    "                );\n",
    "        \"\"\")\n",
    "# Adding the data from the dataframe into the table\n",
    "for i, row in citybikes.iterrows():\n",
    "    c.execute(\"\"\"INSERT INTO stations VALUES (?, ?, ?, ?, ?, ?, ?)\"\"\", row)\n",
    "\n",
    "# Changes being created for database\n",
    "conn.commit()\n",
    "\n",
    "# Closing the connection\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data before and after the join to validate your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Installing required packages\n",
    "pip install pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "## Loading csv file\n",
    "citybikes = pd.read_csv('citybikes.csv')\n",
    "citybikes\n",
    "\n",
    "## Viewing file\n",
    "citybikes\n",
    "\n",
    "## Viewing file\n",
    "citybikes.head()\n",
    "\n",
    "## Viewing data\n",
    "citybikes.describe()\n",
    "\n",
    "## Finding null values\n",
    "citybikes.isnull().sum()\n",
    "\n",
    "## Validating to see if the data frame is empty or not \n",
    "def read_file():\n",
    "    citybikes = pd.read_csv(citybikes)\n",
    "    if(citybikes.empty):\n",
    "        print ('CSV file is empty')\n",
    "    else:\n",
    "        print ('CSV file is not empty')\n",
    "        return citybikes\n",
    "    \n",
    "\n",
    "## File name:\n",
    "filename ='citybikes.csv'\n",
    "\n",
    "## Call the function \n",
    "citybikes = read_file()\n",
    "\n",
    "## Iterating the rows:\n",
    "import pandas as pd\n",
    "citybikes = pd.read_csv(citybikes.csv', nrows=2)\n",
    "for dtype in citybikes.dtypes.iteritems():\n",
    "    print(dtype)\n",
    "                 \n",
    "## Seeing data types:\n",
    "citybikes.types\n",
    "                 \n",
    "## Processing the matched columns\n",
    "import pandas as pd\n",
    "data = pd.read_csv('citybikes.csv')\n",
    "citybikes = citybikes[sorted(data)]\n",
    "validation = citybikes\n",
    "validation['citi'] = validation['BikeStation'].apply(lambda x: True if x in df else False)\n",
    "validation = validation[validation['citi'] == True].reset_index()\n",
    "citybikes\n",
    "                  \n",
    "## Now will convert date column:\n",
    "for col in citybikes.columns:\n",
    "    if citybikes[col].dtype == 'object':\n",
    "        try:\n",
    "            citybikes[col] = pd.to_datetime(citybikes[col])\n",
    "        except ValueError:\n",
    "            pass\n",
    "print(citybikes.dtypes)\n",
    "                 \n",
    "                 \n",
    "## Checking for missing values \n",
    "for col in citybikes.columns:\n",
    "    miss = citybikes[col].isnull().sum()\n",
    "    if miss>0:\n",
    "        print(\"{} has {} missing value(s)\".format(col,miss))\n",
    "    else:\n",
    "        print(\"{} has NO missing value!\".format(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data before and after the join to validate your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at the data before and after the join to validate your data\n",
    "\n",
    "        def create_connection(path):\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = sqlite3.connect(r\"/Users/ibadetazemi/Desktop/Data Science/citybikes.csv\")\n",
    "        print(\"Connection to SQLite DB successful\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "    return connection\n",
    "\n",
    "## Look at the data before and after the join to validate your data\n",
    "    connection = create_connection(\"sm_app.sqlite\")\n",
    "def execute_read_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    result = None\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "\n",
    "select_stationname = \"SELECT Bike Stations from stations\"\n",
    "execute_read_query( connection, select_bikestations )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
